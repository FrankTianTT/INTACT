# env cfg
env_name: CartPoleContinuous-v0
termination_fns: cartpole
reward_fns: ones

# learning
train_frames_per_task: 2000
init_frames_per_task: 50

# planning
planning_horizon: 15
optim_steps: 5
num_candidates: 350
top_k: 35

# model learning
model_type: causal
reinforce: True
batch_size: 256
buffer_size: 10000
model_learning_per_frame: 5
#model_learning_per_frame: 0
train_mask_iters: 10
train_model_iters: 40
world_model_lr: 0.001
context_lr: 0.001
observed_logits_lr: 0.002
context_logits_lr: 0.0005
world_model_weight_decay: 0.001
hidden_size: 256
hidden_layers: 2

lambda_transition: 1.0
lambda_reward: 0.0
lambda_terminated: 0.0
lambda_mutual_info: 0.0

sparse_weight: 0.05
context_sparse_weight: 0.02
context_max_weight: 0.1
sampling_times: 30

# log
exp_name: default
logger: tensorboard
offline_logging: False
eval_interval_frames_per_task: 200
eval_repeat_nums: 3

# meta-RL
meta: True
max_context_dim: 10
task_num: 50
meta_test_task_num: 20
meta_test_interval_frames_per_task: 200
meta_task_adjust_frames_per_task: 50
meta_test_model_learning_per_frame: 5
#meta_test_interval_frames_per_task: 1
#meta_task_adjust_frames_per_task: 1
#meta_test_model_learning_per_frame: 1
oracle_context:
#  gravity: [ 5.0, 20.0 ]
  #  masscart: [ 0.5, 4.5 ]
  x_dot_bias: [ -0.5, 0.5 ]
  theta_dot_bias: [ -0.5, 0.5 ]
#  theta_threshold_degree: [ 10.0, 20.0 ]
new_oracle_context:
  gravity: [ 5.0, 20.0 ]


# other
device: cuda:0