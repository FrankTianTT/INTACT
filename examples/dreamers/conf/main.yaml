defaults:
  - overrides: cartpole
  - _self_

# env cfg
env_name: ${overrides.env_name}
termination_fns: ${overrides.termination_fns}
reward_fns: ${overrides.reward_fns}
env_max_steps: ${overrides.env_max_steps}


train_frames_per_task: 500000
frames_per_batch: 800
init_frames_per_task: 1000

batch_size: 50
batch_length: 25
train_agent_frames: 5000

optim_steps_per_batch: 80
buffer_size: 20000


world_model_lr: 6e-4
actor_value_lr: 8e-5
context_lr: 1e-1
mask_logits_lr: 1e-3

# logger
record_video: 0
record_interval: 1
record_frames: 1000
exp_name: default
logger: tensorboard
offline_logging: False

# model learning
variable_num: 10
state_dim_per_variable: 3
hidden_dim_per_variable: 20
rnn_input_dim_per_variable: 20
sparse_weight: 0.005
context_sparse_weight: 0.01
context_max_weight: 0.2
sampling_times: 30
residual: True
hidden_size: 256
hidden_layers: 4

# meta
meta: False
max_context_dim: 10
task_num: 50


lambda_continue: 10.0

pred_continue: True

train_causal_iters: 0
train_model_iters: 50



# other
model_device: cuda:0
collector_device: cpu
seed: 42

hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    chdir: True
